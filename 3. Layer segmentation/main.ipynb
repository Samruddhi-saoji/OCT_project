{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### read an image ####\n",
    "def read(img_path):\n",
    "   return cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "##### save an image ###\n",
    "def save(img, img_path=\"output.jpeg\"):\n",
    "   cv2.imwrite(img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a list of all the images in a folder ####\n",
    "\n",
    "# returns (list of images, list of names)\n",
    "def list_images(folder_path):\n",
    "    result = []\n",
    "\n",
    "    # get list of names of all the images in the folder\n",
    "    file_names = os.listdir(folder_path)\n",
    "\n",
    "    # read each image as numpy aaray\n",
    "    for img_name in file_names:\n",
    "        # full path of the img = folder_path + image name\n",
    "        image_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "        # Read the image and add it to the list\n",
    "        result.append(read(image_path))\n",
    "\n",
    "    return (result, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a composite image from a list of images\n",
    "\n",
    "# images = list of images\n",
    "def get_composite(images):\n",
    "    # Ensure all images have the same shape\n",
    "    image_shape = images[0].shape\n",
    "    for img in images:\n",
    "        if img.shape != image_shape:\n",
    "            raise ValueError(\"All images must have the same shape\")\n",
    "\n",
    "    # Initialize an array to store the composite image\n",
    "    composite_image = np.zeros_like(images[0], dtype=np.float32)\n",
    "\n",
    "    # Sum the pixel values from all images\n",
    "    for img in images:\n",
    "        composite_image += img.astype(np.float32)\n",
    "\n",
    "    # Normalize the composite image to the range [0, 255]\n",
    "    composite_image = (composite_image / len(images)).astype(np.uint8)\n",
    "\n",
    "    return composite_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Denoising (Adaptive non-local means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### adaptive NLM #####\n",
    "def denoise(img, h=10, window=100, patch=7):\n",
    "    result = cv2.fastNlMeansDenoising(img, None, h=h, templateWindowSize=patch, searchWindowSize=window)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contrast enhancement (custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# contrast enhancement ##################\n",
    "def contrast_enhancement(img, threshold=10, box=(2,4)):\n",
    "    # shape of input image\n",
    "    rows, cols = img.shape\n",
    "\n",
    "    #the result array  #same shape as input\n",
    "    result = img.copy()\n",
    "\n",
    "    # get width and height of the patch (box)\n",
    "    box_width, box_height = box[1], box[0]\n",
    "\n",
    "    # denoise the image one patch at a time\n",
    "    for y in range(0, rows, box_height):\n",
    "        for x in range(0, cols, box_width):\n",
    "            # Extract the patch\n",
    "            patch = img[y:y+box_height, x:x+box_width]\n",
    "\n",
    "            # Calculate the average patch value\n",
    "            avg = np.mean(patch[:,:])\n",
    "\n",
    "            # if the patch average is considered black\n",
    "            if avg <= threshold:\n",
    "                #make the black pixels blacker\n",
    "                patch[patch <= threshold] = patch[patch <= threshold]*(0.8)\n",
    "                \n",
    "                # make the non-black pixels black\n",
    "                patch[patch > threshold] = avg\n",
    "\n",
    "            # Update the patch in the result image\n",
    "            result[y:y+box_height, x:x+box_width] = patch\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image(img, box=(2,4)):\n",
    "    d = denoise(img)\n",
    "    d1 = contrast_enhancement(d, threshold=10, box=box)\n",
    "    d2 = contrast_enhancement(d, threshold= 30, box=box)\n",
    "    d3 = contrast_enhancement(d, threshold=45, box=box)\n",
    "    #d4 = contrast_enhancement(d, threshold=45, box=box)\n",
    "    \n",
    "    images = [d1, d2, d3]\n",
    "\n",
    "    result = get_composite(images)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research paper-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIN filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIN(img):\n",
    "    # normalise ?????\n",
    "    img = np.float32(img) / 255.0\n",
    "\n",
    "    #initialise result image\n",
    "    result = np.zeros_like(img)\n",
    "\n",
    "    # Apply SIN filter\n",
    "    for i in range(img.shape[0]):\n",
    "        result[i, :] = np.sin(img[i, :])\n",
    "\n",
    "    # Convert image back to uint8\n",
    "    result = np.uint8(result * 255.0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfFusionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfFusionNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        out = torch.add(out, x)\n",
    "        return out\n",
    "\n",
    "def self_fusion_NN(img_path, model_path):\n",
    "    # Load OCT B-scan image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = np.float32(img) / 255.0\n",
    "\n",
    "    # Load self-fusion neural network model\n",
    "    model = torch.jit.load(model_path)\n",
    "\n",
    "    # Convert image to tensor\n",
    "    img_tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply self-fusion neural network\n",
    "    with torch.no_grad():\n",
    "        denoised_tensor = model(img_tensor)\n",
    "    denoised_img = denoised_tensor.squeeze().numpy()\n",
    "\n",
    "    # Convert image back to uint8\n",
    "    denoised_img = np.uint8(denoised_img * 255.0)\n",
    "\n",
    "    return denoised_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My subtraction method (experimenting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Smoothening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a patch of size (w,h), make all the pixels in patch equal to the patch average. Do this for both (w,h) and (h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### smoothening the layers #####\n",
    "\n",
    "#smoothen uni directionally\n",
    "def smoothen_uni(img, box=(1,7)):\n",
    "    # shape of image , box\n",
    "    rows, cols = img.shape #image\n",
    "    box_width, box_height = box[1], box[0] #box\n",
    "\n",
    "    #create the the result array  \n",
    "    result = img.copy() #same shape as input\n",
    "\n",
    "    #process the image patch by patch\n",
    "    for y in range(0, rows, box_height):\n",
    "        for x in range(0, cols, box_width):\n",
    "            # Extract the patch\n",
    "            patch = img[y:y+box_height, x:x+box_width]\n",
    "\n",
    "            # Calculate the average patch value\n",
    "            avg = np.mean(patch[:,:])\n",
    "\n",
    "            #make all pixels equal to average\n",
    "            patch[:, :] = avg\n",
    "                \n",
    "            # Update the patch in the result image\n",
    "            result[y:y+box_height, x:x+box_width] = patch\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def smoothen(img, box=(2,5)):\n",
    "    box2 = [box[1], box[0]]\n",
    "\n",
    "    t1 = smoothen_uni(img, box)\n",
    "    t2 = smoothen_uni(img, box2)\n",
    "\n",
    "    result = get_composite([t1, t2])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enhance the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## enhance ###############\n",
    "''' Make all black pixels 0, and all white pixels 255. Leave the grey pixels as it is.'''\n",
    "\n",
    "def process(img):\n",
    "    # shape of image , box\n",
    "    rows, cols = img.shape #image\n",
    "\n",
    "    #create the the result array  \n",
    "    result = img.copy() #same shape as input\n",
    "\n",
    "    #calulate the threshholds\n",
    "    # black = avg pixel value for the entire image\n",
    "    tb = np.mean(img)\n",
    "    # grey threshhold = avg value of non-black pixels\n",
    "    grey_pixels = img[img > tb] #arr of all non-blk pixels\n",
    "    tg = np.mean(grey_pixels)\n",
    "    \n",
    "    # go through the img pixel by pixel\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            pixel = img[y, x]\n",
    "\n",
    "            # make black pixels 0\n",
    "            if pixel <= tb:\n",
    "                result[y, x] = 0\n",
    "            #keep grey pixels as it is\n",
    "            #make white pixels 255\n",
    "            elif pixel > tg:\n",
    "                result[y, x] = 255\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subtract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each pixel, subtract the value of the pixel above it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract(img):\n",
    "    # Create a copy of the input image to store the result\n",
    "    result = img.copy()\n",
    "\n",
    "    # Convert the image data to a 32-bit signed integer data type\n",
    "    # to avoid overflow\n",
    "    img = img.astype(np.int32)\n",
    "\n",
    "    # Calculate the height and width of the image\n",
    "    height, width = img.shape\n",
    "\n",
    "    for y in range(1, height):\n",
    "        for x in range(width):\n",
    "            # Subtract the value of the pixel above from the current pixel\n",
    "            diff = img[y, x] - img[y-1, x]\n",
    "            # Apply ReLU activation\n",
    "            result[y, x] = max(0, diff)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brighten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the picture brighter by increasing the value of each pixel k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brighten(img, k=3):\n",
    "    # Create a copy of the input image to store the result\n",
    "    result = img.copy()\n",
    "\n",
    "    # Brighten the image by multiplying each pixel value by 3\n",
    "    result = result * k\n",
    "\n",
    "    # Clip values to ensure they are within the valid range [0, 255]\n",
    "    result = np.clip(result, 0, 255)\n",
    "\n",
    "    return result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally get the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundaries(img):\n",
    "    temp = smoothen(img, box=(2,5))\n",
    "    temp = subtract(temp)\n",
    "    result = brighten(temp)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, names = list_images(\".\\\\denoised\")\n",
    "\n",
    "count=0\n",
    "for img in images:\n",
    "    result = get_boundaries(img) #some function to process the image\n",
    "    save(result, f\".\\\\output\\\\{names[count]}.jpg\")\n",
    "    count +=1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig = read(\".\\\\originals\\\\f-180.jpg\")\n",
    "# img = denoise_image(orig)\n",
    "\n",
    "img = read(\".\\\\denoised\\\\f-180.jpg.jpg\") #denoised\n",
    "\n",
    "result = get_boundaries(img)\n",
    "\n",
    "save(result, \"output.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
